{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, n_iterations, learning_rate):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.parameters = {}\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        s = 1/(1 + np.nan_to_num(np.exp(-x)))\n",
    "        return s\n",
    "\n",
    "    def initialize_parameters(self, n_features):\n",
    "        W = np.zeros((1, n_features))\n",
    "        b = np.zeros((1, 1))\n",
    "\n",
    "        self.parameters = {\n",
    "            'W': W,\n",
    "            'b': b\n",
    "        }\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        W = self.parameters['W']\n",
    "        b = self.parameters['b']\n",
    "\n",
    "        Z = np.dot(W, X) + b\n",
    "        A = self.sigmoid(Z)\n",
    "\n",
    "        results = {\n",
    "            'Z': Z,\n",
    "            'A': A\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def compute_cost(self, A, Y):\n",
    "        m = Y.shape[1]\n",
    "        \n",
    "        A = np.nan_to_num(A)\n",
    "        logA = np.nan_to_num(np.log(A))\n",
    "        logA_ = np.nan_to_num(np.log(1-A))\n",
    "        \n",
    "        cost = (-1/m)*np.nan_to_num(np.dot(Y, logA.T) + np.dot(1-Y, logA_.T))\n",
    "        cost = np.squeeze(cost)\n",
    "    \n",
    "        return cost\n",
    "\n",
    "    def backward_propagation(self, A, X, Y):\n",
    "        m = Y.shape[1]\n",
    "        dZ = A - Y\n",
    "        dW = np.dot(dZ, X.T)/m\n",
    "        db = np.sum(dZ, axis=1, keepdims=True)\n",
    "\n",
    "        results = {\n",
    "            \"dZ\": dZ,\n",
    "            \"dW\": dW,\n",
    "            \"db\": db\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def gradient_descent(self, X, Y):    \n",
    "        for i in range(self.n_iterations):\n",
    "            A = self.forward_propagation(X)['A']\n",
    "            \n",
    "            if (i+1)%100 == 0:\n",
    "                print(f\"Cost after {i+1} iterations: {self.compute_cost(A, Y)}\")\n",
    "                \n",
    "            gradients = self.backward_propagation(A, X, Y)\n",
    "            self.parameters['W'] = self.parameters['W'] - self.learning_rate*gradients['dW']\n",
    "            self.parameters['b'] = self.parameters['b'] - self.learning_rate*gradients['db']\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        X = np.array(X).T\n",
    "        Y = np.array(Y).reshape(1, -1)\n",
    "\n",
    "        n_features = X.shape[0]\n",
    "        self.initialize_parameters(n_features)\n",
    "\n",
    "        self.gradient_descent(X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X).T\n",
    "        m = X.shape[1]\n",
    "        \n",
    "        W = self.parameters['W']\n",
    "        b = self.parameters['b']\n",
    "\n",
    "        Z = np.dot(W, X) + b\n",
    "        A = self.sigmoid(Z)\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(m):\n",
    "            if A[0, i] > 0.5:\n",
    "                predictions.append(1)\n",
    "            else:\n",
    "                predictions.append(0)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30), (455,), (114,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['data'], dataset['target'], test_size=0.2, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.005e+01, 1.753e+01, 6.441e+01, 3.108e+02, 1.007e-01, 7.326e-02,\n",
       "       2.511e-02, 1.775e-02, 1.890e-01, 6.331e-02, 2.619e-01, 2.015e+00,\n",
       "       1.778e+00, 1.685e+01, 7.803e-03, 1.449e-02, 1.690e-02, 8.043e-03,\n",
       "       2.100e-02, 2.778e-03, 1.116e+01, 2.684e+01, 7.198e+01, 3.840e+02,\n",
       "       1.402e-01, 1.402e-01, 1.055e-01, 6.499e-02, 2.894e-01, 7.664e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15036482, -0.39064196, -1.12855021, -0.95876358,  0.3109837 ,\n",
       "       -0.5959945 , -0.80259612, -0.80249002,  0.29453906,  0.0942515 ,\n",
       "       -0.4950523 ,  1.48720153, -0.51448782, -0.49154005,  0.28149837,\n",
       "       -0.60451206, -0.46900701, -0.61170002,  0.05798237, -0.35763702,\n",
       "       -1.0431756 ,  0.21353282, -1.0360446 , -0.84880771,  0.34249851,\n",
       "       -0.73009743, -0.81232053, -0.75798367, -0.01614761, -0.38503402])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 100 iterations: 0.2340942258824932\n",
      "Cost after 200 iterations: 0.1789840434891524\n",
      "Cost after 300 iterations: 0.15408753529858576\n",
      "Cost after 400 iterations: 0.13918800752674343\n",
      "Cost after 500 iterations: 0.1290154319651974\n",
      "Cost after 600 iterations: 0.12150668727507102\n",
      "Cost after 700 iterations: 0.11567048018240134\n",
      "Cost after 800 iterations: 0.11096497899716708\n",
      "Cost after 900 iterations: 0.10706611101628746\n",
      "Cost after 1000 iterations: 0.10376665838945613\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(n_iterations=1000, learning_rate=0.01)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
